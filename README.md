# maritime-chatter-generation
The maritime industry is the backbone of global trade with more than 80% of the trade volume transported by sea. The safety and the efficiency of the maritime trade suffer from maritime disasters, mainly due to human errors. Therefore, accurate and effective communication in the maritime industry is critical for safety and operational efficiency. Automatic Speech Recognition systems can facilitate better maritime communication. However, an open-source Automatic Speech Recognition training data set in this domain is not available and creating such a dataset containing the chatter and its audio requires significant amount of manual effort. Creating this dataset can be achieved by using a Large Language Model to generate maritime chatters and a Text-to-Speech model to create the audio data. 
To address the problem of data shortage, Llama 3.1 8B model is used to augment an existing manually created dataset of radio chatter instances(seed instances) with an adaptation of the
[Self-Instruct method](https://doi.org/10.48550/arXiv.2212.10560) developed by Wang et. al (2023). Afterwards, the model is fine-tuned with the augmented dataset using Low-Rank Adaptation and prompt-tuning. Large Language Models can be fine-tuned with Low-Rank Adaptation and prompt-tuning to generate realistic and unique maritime radio chatters that comply with the regulations defined in [IMO Standard Maritime Communication Phrases](https://wwwcdn.imo.org/localresources/en/OurWork/Safety/Documents/A.918(22).pdf). Additionally, four evaluation metrics are proposed to assess the correctness of the format, information accuracyand the uniqueness of the maritime distress calls.

See Methodology.md for the details of the methodology.

# Things to do before running any script

- Download the [GSHHG dataset](https://www.soest.hawaii.edu/pwessel/gshhg/). "GSHHS_shp/f/GSHHS_f_L1.shp" file is used in this project. This file should be put in the GSHHS_dataset folder.
- Download the [allCountries.zip](https://download.geonames.org/export/dump/) file from the Geonames dataset. THis file should be put in the all_countries folder.
- Install the libraries in the requirements.txt.
 
# Folders

- all_countries: allCountries.txt file from the geonames data must be in this folder.

- data: Contains the keywords for the Keyword filter and vessel dataset.

- evaluation: Contains the evaluations of other metrics.

	evaluation/{task_name}: Evaluation of chatters generated by LoRA adapters 
	evaluation/prompt_tuning/{task_name}: Evaluation of chatters generated by prompt tuning adapters
	evaluation/vanilla: Evaluation of Chatters generated by the vanilla LLM

- experiments: Contains the snythetic training Chatters.

- GSHHS_dataset: Contains the GSHHS dataset.

- models: Contains the trained LoRA and prompt tuning adapters.

	models/{task_name}: LoRA adapters 
	models/prompt_tuning/{task_name}: Prompt tuning Adapters

- prompts: Contains the instruction part of the instance generation prompts used in the Self-Instruct pipeline.

- scripts: Contains the scripts.

- seed_outputs: Contains the seed instances. seed_outputs.json contains the seed instances. seed_inspect.json contains the context but with more details for possible manual inspections of the contexts. Seed instances are provided for each maritime disaster category defined in the SMCP handbook. You can use your own instances as well.

- synthetic_chatters: Contains the 100 synthetic Chatters generated by LoRA Adapters, prompt tuning adapters and vanilla model.

	synthetic_chatters/{task_name}: Synthetic chatters generated by LoRA adapters 
	synthetic_chatters/prompt_tuning/{task_name}: Synthetic chatters generated by prompt tuning adapters
	synthetic_chatters/vanilla: Synthetic chatters generated by the vanilla LLM	

# Scripts

### geo_test.py ###

Context Generation from the Pipeline mentioned above. A main method is implemented for test purposes only. Make sure to define the necessary paths and numbers in the main method.

### generate_instances_unsloth.py ###

This is the self-instruct pipeline code explained in the methodology chapter. It includes instance generation and filtering. Saves the synthetic chatter to the path ./experiments/{task_name}.
Specify the necessary inputs in the main method.

### lora_finetune.ipynb ###

LoRA code. Saves the LoRA adapters to the folder ./models/{task_name}.

### prompt_tuning.ipynb ###

Prompt tuning code. Saves the adapters to the folder models/prompt_tuning/{task_name}.

### run_models.py, run_models_prompt_tuning.py ###

Loads the LoRA adapters and prompt tuning adapters. 100 synthetic distress calls are generated and saved to paths ./synthetic_chatters/{task_name} and ./synthetic_chatters/prompt_tuning/{task_name}. Variables in the main method should be specified accordingly. 

### inspect_model.py, inspect_model_prompt_tuning.py###

Loads the synthetic calls generated by LoRA adapters and prompt tuning adapters. 100 synthetic distress calls are evaluated and the results ar saved to paths ./evaluation/{task_name} and ./evaluation/prompt_tuning/{task_name}. Variables in the main method should be specified accordingly. 



